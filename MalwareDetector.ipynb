{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476f6a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load the json file with the malware data\n",
    "\n",
    "with open('raw_jsons_labeled_SAVE.json', 'r') as file:\n",
    "    data = json.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b10ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization\n",
    "\n",
    "import re\n",
    "\n",
    "def tokenize_path(path):\n",
    "    \n",
    "    # Path is empty\n",
    "    if path == '':\n",
    "        return []\n",
    "    \n",
    "    # Regex pattern to split by backslashes, forward slashes, spaces, and tabs\n",
    "    pattern = r'[\\\\/ \\t,]+'\n",
    "    \n",
    "    # Tokens after spliting\n",
    "    tokens = re.split(pattern, path) \n",
    "    \n",
    "    return [token for token in tokens if token] # Remove empty tokens\n",
    "\n",
    "\n",
    "documents = {} # Key-value pairs of processGuid and token list\n",
    "malicious_labels = {} # Key-value pairs of processGuid and isMalicious labels\n",
    "for key, value in data.items():\n",
    "    for event in value:\n",
    "        # Navigate to the 'eventdata' dictionary\n",
    "        eventdata = event['data']['win']['eventdata']\n",
    "        \n",
    "        # Tokens\n",
    "        originalFileName_tokens = []\n",
    "        image_tokens = []\n",
    "        imageLoaded_tokens = []\n",
    "        commandLine_tokens = []\n",
    "        \n",
    "        # Tokenize 'originalFileName', if it exists\n",
    "        if 'originalFileName' in eventdata:\n",
    "            originalFileName_tokens = tokenize_path(eventdata['originalFileName'])\n",
    "        \n",
    "        # Tokenize 'image', if it exists\n",
    "        if 'image' in eventdata:\n",
    "            image_tokens = tokenize_path(eventdata['image'])\n",
    "        \n",
    "        # Tokenize 'imageLoaded', if it exists\n",
    "        if 'imageLoaded' in eventdata:\n",
    "            imageLoaded_tokens = tokenize_path(eventdata['imageLoaded'])\n",
    "        \n",
    "        # Tokenize 'commandLine', if it exists\n",
    "        if 'commandLine' in eventdata:\n",
    "            commandLine_tokens = tokenize_path(eventdata['commandLine'])\n",
    "        \n",
    "        # Combine the tokens and get rid of duplicates\n",
    "        combined_tokens = set(originalFileName_tokens + image_tokens + imageLoaded_tokens + commandLine_tokens)\n",
    "        \n",
    "        # Convert the combined_tokens set to a list\n",
    "        tokens_list = list(combined_tokens)\n",
    "        \n",
    "        # Add key-value pair of processGuid and tokens_list in documents\n",
    "        documents[eventdata.get('processGuid')] = tokens_list\n",
    "        \n",
    "        # Add key-value pair of processGuid and isMalicious labels\n",
    "        malicious_labels[eventdata.get('processGuid')] = event['IsMalicious']\n",
    "        \n",
    "print(malicious_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8682411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the document dictionary into training, testing and validation sets\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Convert the documents and labels into a format suitable for scikit-learn\n",
    "process_guids = list(documents.keys())\n",
    "X = list(documents.values())\n",
    "y = [malicious_labels[guid] for guid in process_guids]\n",
    "\n",
    "# Split the data into training, validation, and testing sets (70-15-15 split)\n",
    "X_train, X_temp, y_train, y_temp, process_guids_train, process_guids_temp = train_test_split(X, y, process_guids, test_size=0.3, random_state=42)\n",
    "X_valid, X_test, y_valid, y_test, process_guids_valid, process_guids_test = train_test_split(X_temp, y_temp, process_guids_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Create a dictionary for the training data\n",
    "documents_training = {guid: documents[guid] for guid in process_guids_train}\n",
    "\n",
    "# Create a dictionary for the validation data\n",
    "documents_validation = {guid: documents[guid] for guid in process_guids_valid}\n",
    "\n",
    "# Create a dictionary for the testing data\n",
    "documents_test = {guid: documents[guid] for guid in process_guids_test}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c055719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequency Table\n",
    "\n",
    "import gensim\n",
    "from gensim.corpora import Dictionary\n",
    "\n",
    "# Tokenize the documents\n",
    "tokenized_documents = list(documents_training.values())\n",
    "\n",
    "lower_bound = 5 # Lower bound threshold\n",
    "upper_bound_percentage = 95 # Tokens appearing in more than 95% of documents\n",
    "upper_bound = upper_bound_percentage * len(tokenized_documents) / 100 # Upper bound threshold\n",
    "\n",
    "# Create a Gensim dictionary from the tokenized documents\n",
    "dictionary = Dictionary(tokenized_documents)\n",
    "\n",
    "# Calculate the document frequency for each token\n",
    "document_frequencies = {dictionary.get(token_id): dictionary.dfs[token_id] for token_id in dictionary.dfs}\n",
    "\n",
    "# Filter out tokens with a document frequency less than 5\n",
    "tokens_to_remove = [token for token, freq in document_frequencies.items() if freq <= lower_bound or freq > upper_bound]\n",
    "for token in tokens_to_remove:\n",
    "    del document_frequencies[token]\n",
    "\n",
    "print(document_frequencies)\n",
    "print(len(document_frequencies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15312f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Filter the Gensim dictionary to keep only tokens in document_frequencies\n",
    "filtered_token_ids = [dictionary.token2id[token] for token in document_frequencies]\n",
    "dictionary.filter_tokens(bad_ids=None, good_ids=filtered_token_ids)\n",
    "\n",
    "# Prepare the Training DataFrame\n",
    "# Rows are processGuid\n",
    "# Columns are the token IDs of the filtered tokens\n",
    "\n",
    "# Create a DataFrame with zeros, with filtered token IDs as columns\n",
    "df = pd.DataFrame(0, index=process_guids_train, columns=filtered_token_ids)\n",
    "\n",
    "for guid in process_guids_train:\n",
    "    doc = documents_training[guid]\n",
    "    # Ensure we only access tokens that are in the dictionary\n",
    "    token_ids = []\n",
    "    for token in doc:\n",
    "        if token in dictionary.token2id:\n",
    "            token_id = dictionary.token2id[token]\n",
    "            token_ids.append(token_id)\n",
    "    df.loc[guid, token_ids] = 1\n",
    "\n",
    "# df now contains your binary matrix\n",
    "\n",
    "# Prepare the Validation DataFrame\n",
    "# Rows are processGuid\n",
    "# Columns are the token IDs of the filtered tokens\n",
    "df_valid = pd.DataFrame(0, index=process_guids_valid, columns=filtered_token_ids)\n",
    "\n",
    "for guid in process_guids_valid:\n",
    "    doc = documents_validation[guid]\n",
    "    # Ensure we only access tokens that are in the dictionary\n",
    "    token_ids = []\n",
    "    for token in doc:\n",
    "        if token in dictionary.token2id:\n",
    "            token_id = dictionary.token2id[token]\n",
    "            token_ids.append(token_id)\n",
    "    df_valid.loc[guid, token_ids] = 1\n",
    "\n",
    "# Prepare the Testing DataFrame\n",
    "# Rows are processGuid\n",
    "# Columns are the token IDs of the filtered tokens\n",
    "df_test = pd.DataFrame(0, index=process_guids_test, columns=filtered_token_ids)\n",
    "\n",
    "for guid in process_guids_test:\n",
    "    doc = documents_test[guid]\n",
    "    # Ensure we only access tokens that are in the dictionary\n",
    "    token_ids = []\n",
    "    for token in doc:\n",
    "        if token in dictionary.token2id:\n",
    "            token_id = dictionary.token2id[token]\n",
    "            token_ids.append(token_id)\n",
    "    df_test.loc[guid, token_ids] = 1\n",
    "\n",
    "print(\"Training DataFrame\")\n",
    "print(df)\n",
    "\n",
    "print(\"Validation DataFrame\")\n",
    "print(df_valid)\n",
    "\n",
    "print(\"Testing DataFrame\")\n",
    "print(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7231795",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Initialize the Logistic Regression model\n",
    "logreg = LogisticRegression(penalty='l1', solver='liblinear', random_state=42)\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 40, 100]}\n",
    "\n",
    "# Set up GridSearchCV\n",
    "grid_search = GridSearchCV(logreg, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit GridSearchCV to the training data\n",
    "grid_search.fit(df, y_train)\n",
    "\n",
    "# Print the best parameters\n",
    "print(\"Best parameters found:\", grid_search.best_params_)\n",
    "\n",
    "# Evaluate the best model on the validation dataset\n",
    "best_model = grid_search.best_estimator_\n",
    "validation_accuracy = best_model.score(df_valid, y_valid)\n",
    "print(\"Validation accuracy:\", validation_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449f8689",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score\n",
    "\n",
    "# Assume best_model is your trained model and df_valid, y_valid are your validation features and labels\n",
    "y_pred = best_model.predict(df_valid)\n",
    "\n",
    "print(\"Validation Set\")\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_valid, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Precision\n",
    "precision = precision_score(y_valid, y_pred)\n",
    "print(\"Precision:\", precision)\n",
    "\n",
    "# Recall\n",
    "recall = recall_score(y_valid, y_pred)\n",
    "print(\"Recall:\", recall)\n",
    "\n",
    "# Accuracy\n",
    "accuracy = accuracy_score(y_valid, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1b8b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume best_model is your trained model and df_test, y_test are your validation features and labels\n",
    "y_pred = best_model.predict(df_test)\n",
    "\n",
    "print(\"Testing Set\")\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Precision\n",
    "precision = precision_score(y_test, y_pred)\n",
    "print(\"Precision:\", precision)\n",
    "\n",
    "# Recall\n",
    "recall = recall_score(y_test, y_pred)\n",
    "print(\"Recall:\", recall)\n",
    "\n",
    "# Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e571d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Extract the coefficients and convert them into a DataFrame\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Token': [dictionary.get(token_id) for token_id in filtered_token_ids],\n",
    "    'Coefficient': best_model.coef_[0]\n",
    "})\n",
    "\n",
    "# Sort the tokens by their coefficient values to see the most important features\n",
    "feature_importance = feature_importance.sort_values(by='Coefficient', ascending=False)\n",
    "\n",
    "print(feature_importance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e4f304",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Initialize the Random Forest classifier\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Define a grid of parameters to search over\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],  # Number of trees in the forest\n",
    "    'max_depth': [10, 20, 30],        # Maximum depth of the tree\n",
    "    'max_features': ['sqrt'], # Number of features to consider at every split\n",
    "    # Add more parameters here if needed\n",
    "}\n",
    "\n",
    "# Set up GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, \n",
    "                           cv=5, n_jobs=-1, verbose=2, scoring='accuracy')\n",
    "\n",
    "# Fit GridSearchCV to the training data\n",
    "grid_search.fit(df, y_train)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best parameters:\", best_params)\n",
    "\n",
    "# Evaluate the best model on the validation dataset\n",
    "best_rf_model = grid_search.best_estimator_\n",
    "validation_accuracy = best_rf_model.score(df_valid, y_valid)\n",
    "print(\"Validation accuracy with best parameters:\", validation_accuracy)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
